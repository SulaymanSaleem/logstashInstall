#s3_input conf


# Sample Logstash configuration for creating a simple
# AWS S3 -> Logstash -> Elasticsearch pipeline.
# References:
#   https://www.elastic.co/guide/en/logstash/current/plugins-inputs-s3.html
#   https://www.elastic.co/blog/logstash-lines-inproved-resilience-in-S3-input
#   https://www.elastic.co/guide/en/logstash/current/working-with-plugins.html

input {
  s3 {
    region => "eu-west-1"
    bucket => "'$BUCKET"
    interval => "10"
    additional_settings => {
      force_path_style => true
      follow_redirects => false
                }
  }
}

filter {
      csv {
        convert => {
          "column1" => "float"
          "column2" => "float"
	  "column3" => "float"
          "column4" => "float"
        }
      }
    }


output {
  elasticsearch {
    hosts => ["https://${ES_HOST}:9200"]
    cacert =>"/etc/logstash/conf.d/ca.crt"
    index => "logs-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "${ES_PASSWORD}"
  }
}

